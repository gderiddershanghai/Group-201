{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886d71a-b613-434b-a1e2-e0ab12c09ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder Structure:\n",
    "# simple_feature_extraction.ipynb (this script)\n",
    "\n",
    "# asap-aes (folder)\n",
    "## training_set_rel3.tsv\n",
    "\n",
    "# supplementary_data\n",
    "## Kuperman-BRM-data-2012.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3c7dd-8201-446c-9679-0ec359acd4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import scipy\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import warnings\n",
    "import textstat\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "import pyphen\n",
    "import syllapy\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import spacy\n",
    "#python3 -m spacy download en_core_web_md\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "# import gingerit\n",
    "# import languagetool_python\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f97390-d8a6-42cb-9cb0-22d5806d6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_training_set = pd.read_csv('asap-aes/training_set_rel3.tsv',sep='\\t', encoding='latin1')\n",
    "#raw_training_set_chunked = pd.read_csv('processed_data/train_chunked_processed.csv', encoding='latin1')\n",
    "#raw_training_set_original = pd.read_csv('processed_data/train_full_processed.csv', encoding='latin1')\n",
    "raw_training_set = pd.read_csv('processed_data/train_full_processed.csv', encoding='latin1')\n",
    "aoa_df = pd.read_csv('supplementary_data/Kuperman-BRM-data-2012.csv') # age of acquisition\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc534540-f90f-4de3-a497-41cde2bee45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_training_set.shape)\n",
    "print(raw_training_set.columns)\n",
    "raw_training_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da8c1a-89cd-4223-8eea-e1eeb29c5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_set[['essay_set', 'rescaled_score']].groupby('essay_set', as_index = False).agg(['count', 'mean', 'max', 'min', 'std']).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849832b-90be-4162-bc9f-e6ae958ddff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_set.isna().any(axis = 0)\n",
    "#raw_training_set.isna().all(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70870c-5fa2-4147-9663-ac5cf9136472",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_str = raw_training_set['essay'][10]\n",
    "essay_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3ee55-5753-40c5-ae9b-14eec1b37e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(essay_str):\n",
    "\n",
    "    words = essay_str.split(' ')\n",
    "    words = [w for w in words if len(w) > 0]\n",
    "    words = [w for w in words if w[0] != '@']\n",
    "    words = [w.lower() for w in words]\n",
    "    #tokens = word_tokenize(essay_str)\n",
    "    \n",
    "    idx_set1 = math.floor(len(words) / 3)\n",
    "    idx_set2 = idx_set1 + idx_set1\n",
    "    \n",
    "    text_set1, text_set2, text_set3 = words[:idx_set1], words[idx_set1:idx_set2], words[idx_set2:]\n",
    "    text_set1, text_set2, text_set3 = ' '.join(text_set1), ' '.join(text_set2), ' '.join(text_set3)\n",
    "    #print(len(text_set1), len(text_set2), len(text_set3))\n",
    "\n",
    "    return text_set1, text_set2, text_set3\n",
    "\n",
    "\n",
    "def remove_punctuations(x):\n",
    "    return [re.sub(r'[^\\w\\s]', '', token) for token in x if re.sub(r'[^\\w\\s]', '', token)]\n",
    "\n",
    "def get_avg_AoA(tokens):\n",
    "    tokens_df = pd.DataFrame({'token': tokens})\n",
    "    tokens_df = pd.merge(tokens_df, aoa_df[['Word', 'Rating.Mean']], left_on = 'token', right_on = 'Word', how = 'left')\n",
    "    \n",
    "    if tokens_df['Rating.Mean'].isna().all():\n",
    "        avg_aoa = 0\n",
    "    else:\n",
    "        avg_aoa = tokens_df['Rating.Mean'].mean()\n",
    "\n",
    "    return avg_aoa\n",
    "\n",
    "def get_cohesion_score(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # obtain vectors of size (300, ) for each word in the text\n",
    "    vec_tokens = [token.vector for token in doc if token.has_vector and not token.is_stop and not token.is_punct]\n",
    "\n",
    "    # calculate cosine similarity score for combinations of two vectors\n",
    "    if (len(vec_tokens) > 2):\n",
    "        similarities = [np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "                        for v1, v2 in combinations(vec_tokens, 2)]\n",
    "        if (len(similarities) > 0):\n",
    "            return np.mean(similarities)\n",
    "        else:\n",
    "            #print('similarity = 0')\n",
    "            return np.nan()\n",
    "    else:\n",
    "        #print('token too small')\n",
    "        return np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ae41a-f8d5-4a2e-95e6-6c2625b4c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_training_df = raw_training_set[['essay_id', 'essay_set', 'essay']].head(200).copy() # take the first 200 rows to prototype faster\n",
    "text_training_df = raw_training_set.loc[raw_training_set['essay_set'].isin([1, 3, 4, 5, 6]), ['essay_id', 'essay_set', 'essay']].copy()\n",
    "\n",
    "# converting to lower case and removing words replaced starting with @\n",
    "# text_training_df['text'] = text_training_df['essay'].apply(lambda x: pd.Series(get_text(x)))\n",
    "\n",
    "# split each essay into 3 sets, and keep the original essay labeled as \"text_original\"\n",
    "text_training_df[['text_set1', 'text_set2', 'text_set3']] = text_training_df['essay'].progress_apply(lambda x: pd.Series(get_sets(x)))\n",
    "text_training_df = text_training_df.rename(columns = {'essay': 'text_original'})\n",
    "text_training_df = text_training_df.melt(id_vars=['essay_id', 'essay_set'], value_vars=['text_set1', 'text_set2', 'text_set3', 'text_original'],\n",
    "                                        var_name='text_set', value_name='text')\n",
    "\n",
    "\n",
    "# tokenize into words and sentences\n",
    "text_training_df['word_tokens'] = text_training_df['text'].progress_apply(lambda x: word_tokenize(x))\n",
    "text_training_df['sent_tokens'] = text_training_df['text'].progress_apply(lambda x: sent_tokenize(x))\n",
    "text_training_df['word_tokens_clean'] = text_training_df['word_tokens'].progress_apply(lambda x: remove_punctuations(x))\n",
    "\n",
    "text_training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490251cf-a042-4c65-99cb-6713094a81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_training_df.groupby('essay_set', as_index = False).count()\n",
    "# raw_training_set[raw_training_set['essay_id'] == 1171]\n",
    "# text_training_df[text_training_df['essay_id'] == 1171]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda90f9-cf77-4a42-b39a-76f44f0ecfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract basic statistical features\n",
    "# (1) total number of words \n",
    "# (2) total number of characters\n",
    "# (3) average number of words per sentence\n",
    "# (4) total number of sentences\n",
    "# (5) total number of paragraphs, ---> I don't think we can do this, doesn't seem to be in the raw data\n",
    "# (6) total number of spelling mistakes\n",
    "# (7) total number of grammar mistakes ---> I tried multiple packages but no luck. Textblob and transformer worked, but test cases are wrong. Skipped for now. \n",
    "# Flesch-Kincaid Score\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "text_training_df['word_count'] = text_training_df['word_tokens_clean'].progress_apply(lambda x: len(x))\n",
    "text_training_df['sent_count'] = text_training_df['sent_tokens'].progress_apply(lambda x: len(x))\n",
    "text_training_df['char_count'] = text_training_df['text'].progress_apply(lambda x: len(x))\n",
    "text_training_df['sent_length'] = text_training_df['word_count'] / text_training_df['sent_count']\n",
    "\n",
    "spellcheck = SpellChecker()\n",
    "text_training_df['spell_err_count'] = text_training_df['word_tokens_clean'].progress_apply(lambda x: len(spellcheck.unknown(x)))\n",
    "text_training_df['syllabus_count'] = text_training_df['word_tokens_clean'].progress_apply(lambda x: sum(syllapy.count(word) for word in x))\n",
    "#text_training_df['FleKin_score'] = (0.39 * (text_training_df['word_count'] / text_training_df['sent_count'])) + (11.8 * (text_training_df['syllabus_count'] / text_training_df['word_count'])) - 15.59\n",
    "# the scores generated from this formula is very different from using flesch_reading_ease\n",
    "# the formula is also different from wikipedia. Where did you get this?\n",
    "\n",
    "# text_training_df['FleKin_score'] = 206.835 - (1.015 * (text_training_df['word_count'] / text_training_df['sent_count'])) - (84.6 * (text_training_df['syllabus_count'] / text_training_df['word_count']))\n",
    "# this formula is from Wikipedia and close to the result of using flesch_reading_ease\n",
    "\n",
    "text_training_df['FleKin_score'] = text_training_df['text'].progress_apply(lambda x: textstat.flesch_reading_ease(x))\n",
    "\n",
    "# extras, not in the proposal\n",
    "text_training_df['DalCha_score'] = text_training_df['text'].progress_apply(lambda x: textstat.dale_chall_readability_score(x))\n",
    "text_training_df['unique_word_count'] = text_training_df['word_tokens_clean'].progress_apply(lambda x: len(set(w.lower() for w in x)))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Time taken for basic statistical feature extraction: {execution_time:.5f} seconds\")\n",
    "\n",
    "text_training_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25a0c9-4769-4fb4-8b11-86f8292ea1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mauryquijada/word-complexity-predictor/tree/master\n",
    "# Supposed to be able to extract these features using machine learning techniques:\n",
    "    # Lemma length\n",
    "    # Average age-of-acquisition (at what age a word is most likely to enter someone's vocabulary)\n",
    "    # Average concreteness (a score of 1 to 5, with 5 being very concrete)\n",
    "    # Frequency in a certain corpus\n",
    "    # Lemma frequency in a certain corpus\n",
    "        \n",
    "# text_training_df['text'].apply(lambda x: get_cohesion_score(x)).isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6689db-1c43-4852-9b6d-59f4b4acec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() # takes about 30 seconds, mostly on the cohesion score calculation\n",
    "# text_training_df = text_training_df.head(100).copy()\n",
    "# content feature extraction \n",
    "## sentiments (4 metrics)\n",
    "## cohesion score, calculated as cosine similarity\n",
    "## Age of Acquisision score, mapped from the Kuperman dataset\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "text_training_df[['neg', 'neu', 'pos', 'compound']] = text_training_df['text'].progress_apply(lambda x: list(analyzer.polarity_scores(x).values())).apply(pd.Series)\n",
    "text_training_df['cohesion'] = text_training_df['text'].progress_apply(lambda x: get_cohesion_score(x))\n",
    "text_training_df['AoA_score'] = text_training_df['word_tokens_clean'].progress_apply(lambda x: get_avg_AoA(x))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Time taken for basic content feature extraction: {execution_time:.5f} seconds\")\n",
    "\n",
    "text_training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4cc1c3-6422-48aa-af68-d936862b0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_feature_train = text_training_df.merge(raw_training_set[['essay_id', 'rescaled_score', 'low_med_hi',\n",
    "                                                               'low_med_hi_numeric']], on = ['essay_id'], how = 'left')\n",
    "\n",
    "\n",
    "basic_feature_train.to_csv('scaled_feature_train_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
