{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8843103-14ac-4e29-9f79-df367bf4a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import scipy\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import datetime\n",
    "# import warnings\n",
    "# import spacy\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, mean_squared_error, make_scorer, mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import clear_output\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453fd2c8-00c4-4b06-aa10-04901e228b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_feature_train_df = pd.read_csv('scaled_feature_train_data.csv') \n",
    "test_data = pd.read_csv('basic_test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "600d132a-3af3-45f6-b65e-675587c6d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "(28436, 25)\n",
      "Index(['essay_id', 'essay_set', 'text_set', 'text', 'word_tokens',\n",
      "       'sent_tokens', 'word_tokens_clean', 'word_count', 'sent_count',\n",
      "       'char_count', 'sent_length', 'spell_err_count', 'syllabus_count',\n",
      "       'FleKin_score', 'DalCha_score', 'unique_word_count', 'neg', 'neu',\n",
      "       'pos', 'compound', 'cohesion', 'AoA_score', 'rescaled_score',\n",
      "       'low_med_hi', 'low_med_hi_numeric'],\n",
      "      dtype='object')\n",
      "Test data\n",
      "(7108, 25)\n",
      "Index(['essay_id', 'essay_set', 'text_set', 'text', 'word_tokens',\n",
      "       'sent_tokens', 'word_tokens_clean', 'word_count', 'sent_count',\n",
      "       'char_count', 'sent_length', 'spell_err_count', 'syllabus_count',\n",
      "       'FleKin_score', 'DalCha_score', 'unique_word_count', 'neg', 'neu',\n",
      "       'pos', 'compound', 'cohesion', 'AoA_score', 'rescaled_score',\n",
      "       'low_med_hi', 'low_med_hi_numeric'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Training data')\n",
    "print(basic_feature_train_df.shape)\n",
    "print(basic_feature_train_df.columns)\n",
    "\n",
    "print('Test data')\n",
    "print(test_data.shape)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a064e6d-097a-4fe3-9fe7-149ac4220281",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['word_count', 'sent_count', 'char_count', 'sent_length', 'spell_err_count', 'syllabus_count',\n",
    "                'FleKin_score', 'DalCha_score', 'unique_word_count', 'neg', 'neu', 'pos', 'compound', 'cohesion', 'AoA_score']\n",
    "\n",
    "def data_selection(data, feature_cols, essay_set, text_set, is_test = False, is_regression = False, labelencoder = False):\n",
    "    df = data.copy()\n",
    "    df = df[df['essay_set'].isin(essay_set)]\n",
    "    df = df[~df['rescaled_score'].isna()]\n",
    "    df = df[~df['cohesion'].isna()]\n",
    "    #print(len(df))\n",
    "    if is_test == False:\n",
    "       df = df[~(df['essay_id'] == 10001)] # the text is \"NO IMAGE\"\n",
    "    \n",
    "\n",
    "    if text_set == 'subset':\n",
    "        X = df.loc[df['text_set'] != 'text_original', feature_cols]\n",
    "        if is_regression:\n",
    "            y = np.array(df.loc[df['text_set'] != 'text_original', 'rescaled_score'])\n",
    "        else:\n",
    "            y = np.array(df.loc[df['text_set'] != 'text_original', 'rescaled_score']).round()\n",
    "    elif text_set == 'original':\n",
    "        X = df.loc[df['text_set'] == 'text_original', feature_cols]\n",
    "        if is_regression:\n",
    "            y = np.array(df.loc[df['text_set'] == 'text_original', 'rescaled_score'])\n",
    "        else:\n",
    "            y = np.array(df.loc[df['text_set'] == 'text_original', 'rescaled_score']).round()\n",
    "\n",
    "    if labelencoder:\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y)\n",
    "\n",
    "    #print('>>> is_test:', is_test)\n",
    "    print('X:', X.shape, 'y:', y.shape)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097fe9aa-2d92-42f9-9b75-baeea029e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_randforest_classifier(text_set_, essay_set_):\n",
    "    overall_params = {\n",
    "        'model': 'Random Forest', \n",
    "        'text_set': text_set_,      # 'subset', or 'original' \n",
    "        'essay_set': essay_set_,          # [1, 3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "    print(\"#######\", overall_params)\n",
    "    \n",
    "    X_train, y_train = data_selection(basic_feature_train_df, feature_cols, overall_params['essay_set'], overall_params['text_set'])\n",
    "    X_test, y_test = data_selection(test_data, feature_cols, overall_params['essay_set'], overall_params['text_set'], is_test = True)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Step 1: Standardize features\n",
    "        ('pca', PCA(n_components=0.9)),  # Step 2: Perform PCA (reduce to 2 components)\n",
    "        ('rf', RandomForestClassifier(random_state=42, max_depth = 20, \n",
    "                                        min_samples_leaf = 2, \n",
    "                                        min_samples_split = 8,\n",
    "                                        n_estimators = 150))  # Step 3: Random Forest\n",
    "    ])\n",
    "    \n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Test the pipeline\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    qwk  = cohen_kappa_score(y_pred, y_test, weights = 'quadratic')\n",
    "    \n",
    "\n",
    "    return y_pred, qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3201bd5e-bfee-42bd-af42-96933a622eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xgb_classifier(text_set_, essay_set_):\n",
    "    overall_params = {\n",
    "        'model': 'XGB Classifier', \n",
    "        'text_set': text_set_,      # 'subset', or 'original' \n",
    "        'essay_set': essay_set_,          # [1, 3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "    print(\"#######\", overall_params)\n",
    "\n",
    "    X_train, y_train = data_selection(basic_feature_train_df, feature_cols, overall_params['essay_set'], overall_params['text_set'], is_test = False, is_regression = False, labelencoder = True)\n",
    "    X_test, y_test = data_selection(test_data, feature_cols, overall_params['essay_set'], overall_params['text_set'], is_test = True, is_regression = False, labelencoder = True)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Step 1: Standardize features\n",
    "        ('pca', PCA(n_components=0.9)),  # Step 2: Perform PCA\n",
    "        ('xgb', XGBClassifier(eval_metric=mean_absolute_error, \n",
    "                                random_state=45, \n",
    "                                colsample_bytree = 0.8, \n",
    "                                gamma = 1,\n",
    "                                learning_rate = 0.3, \n",
    "                                max_depth = 3, \n",
    "                                n_estimators = 100))  \n",
    "                                ])\n",
    "    \n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Test the pipeline\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    qwk  = cohen_kappa_score(y_pred, y_test, weights = 'quadratic')\n",
    "\n",
    "    return y_pred, qwk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a2285f-6372-443f-927e-14be7c150459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xgb_regressor(text_set_, essay_set_):\n",
    "    overall_params = {\n",
    "        'model': 'XGB Regressor', \n",
    "        'text_set': text_set_,      # 'subset', or 'original' \n",
    "        'essay_set': essay_set_,          # [1, 3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "    print(\"#######\", overall_params)\n",
    "\n",
    "    X_train, y_train = data_selection(basic_feature_train_df, feature_cols, overall_params['essay_set'], overall_params['text_set'], is_test = False, is_regression = True, labelencoder = True)\n",
    "    X_test, y_test = data_selection(test_data, feature_cols, overall_params['essay_set'], overall_params['text_set'], is_test = True, is_regression = True, labelencoder = True)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Step 1: Standardize features\n",
    "        ('pca', PCA(n_components=0.9)),  # Step 2: Perform PCA\n",
    "        ('xgb', XGBRegressor(random_state=42,\n",
    "                            gamma=1, learning_rate=0.2, max_depth=2, n_estimators=100, reg_alpha=0.1, reg_lambda=1))\n",
    "                                ])\n",
    "    \n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Test the pipeline\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred = y_pred.round().astype(int)\n",
    "    qwk  = cohen_kappa_score(y_pred, y_test, weights = 'quadratic')\n",
    "    \n",
    "    return y_pred, qwk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667b3bfa-7747-4318-9e16-f2fcf7aa0f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### {'model': 'Random Forest', 'text_set': 'original', 'essay_set': [1]}\n",
      "X: (1426, 15) y: (1426,)\n",
      "X: (357, 15) y: (357,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'original', 'essay_set': [3]}\n",
      "X: (1381, 15) y: (1381,)\n",
      "X: (344, 15) y: (344,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'original', 'essay_set': [4]}\n",
      "X: (1416, 15) y: (1416,)\n",
      "X: (352, 15) y: (352,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'original', 'essay_set': [5]}\n",
      "X: (1443, 15) y: (1443,)\n",
      "X: (361, 15) y: (361,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'original', 'essay_set': [6]}\n",
      "X: (1440, 15) y: (1440,)\n",
      "X: (358, 15) y: (358,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'original', 'essay_set': [1, 3, 4, 5, 6]}\n",
      "X: (7106, 15) y: (7106,)\n",
      "X: (1772, 15) y: (1772,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'subset', 'essay_set': [1]}\n",
      "X: (4270, 15) y: (4270,)\n",
      "X: (1069, 15) y: (1069,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'subset', 'essay_set': [3]}\n",
      "X: (4075, 15) y: (4075,)\n",
      "X: (1011, 15) y: (1011,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'subset', 'essay_set': [4]}\n",
      "X: (4102, 15) y: (4102,)\n",
      "X: (1004, 15) y: (1004,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'subset', 'essay_set': [5]}\n",
      "X: (4251, 15) y: (4251,)\n",
      "X: (1065, 15) y: (1065,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'subset', 'essay_set': [6]}\n",
      "X: (4300, 15) y: (4300,)\n",
      "X: (1070, 15) y: (1070,)\n",
      "####### {'model': 'Random Forest', 'text_set': 'subset', 'essay_set': [1, 3, 4, 5, 6]}\n",
      "X: (20998, 15) y: (20998,)\n",
      "X: (5219, 15) y: (5219,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'original', 'essay_set': [1]}\n",
      "X: (1426, 15) y: (1426,)\n",
      "X: (357, 15) y: (357,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'original', 'essay_set': [3]}\n",
      "X: (1381, 15) y: (1381,)\n",
      "X: (344, 15) y: (344,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'original', 'essay_set': [4]}\n",
      "X: (1416, 15) y: (1416,)\n",
      "X: (352, 15) y: (352,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'original', 'essay_set': [5]}\n",
      "X: (1443, 15) y: (1443,)\n",
      "X: (361, 15) y: (361,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'original', 'essay_set': [6]}\n",
      "X: (1440, 15) y: (1440,)\n",
      "X: (358, 15) y: (358,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'original', 'essay_set': [1, 3, 4, 5, 6]}\n",
      "X: (7106, 15) y: (7106,)\n",
      "X: (1772, 15) y: (1772,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'subset', 'essay_set': [1]}\n",
      "X: (4270, 15) y: (4270,)\n",
      "X: (1069, 15) y: (1069,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'subset', 'essay_set': [3]}\n",
      "X: (4075, 15) y: (4075,)\n",
      "X: (1011, 15) y: (1011,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'subset', 'essay_set': [4]}\n",
      "X: (4102, 15) y: (4102,)\n",
      "X: (1004, 15) y: (1004,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'subset', 'essay_set': [5]}\n",
      "X: (4251, 15) y: (4251,)\n",
      "X: (1065, 15) y: (1065,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'subset', 'essay_set': [6]}\n",
      "X: (4300, 15) y: (4300,)\n",
      "X: (1070, 15) y: (1070,)\n",
      "####### {'model': 'XGB Classifier', 'text_set': 'subset', 'essay_set': [1, 3, 4, 5, 6]}\n",
      "X: (20998, 15) y: (20998,)\n",
      "X: (5219, 15) y: (5219,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'original', 'essay_set': [1]}\n",
      "X: (1426, 15) y: (1426,)\n",
      "X: (357, 15) y: (357,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'original', 'essay_set': [3]}\n",
      "X: (1381, 15) y: (1381,)\n",
      "X: (344, 15) y: (344,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'original', 'essay_set': [4]}\n",
      "X: (1416, 15) y: (1416,)\n",
      "X: (352, 15) y: (352,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'original', 'essay_set': [5]}\n",
      "X: (1443, 15) y: (1443,)\n",
      "X: (361, 15) y: (361,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'original', 'essay_set': [6]}\n",
      "X: (1440, 15) y: (1440,)\n",
      "X: (358, 15) y: (358,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'original', 'essay_set': [1, 3, 4, 5, 6]}\n",
      "X: (7106, 15) y: (7106,)\n",
      "X: (1772, 15) y: (1772,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'subset', 'essay_set': [1]}\n",
      "X: (4270, 15) y: (4270,)\n",
      "X: (1069, 15) y: (1069,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'subset', 'essay_set': [3]}\n",
      "X: (4075, 15) y: (4075,)\n",
      "X: (1011, 15) y: (1011,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'subset', 'essay_set': [4]}\n",
      "X: (4102, 15) y: (4102,)\n",
      "X: (1004, 15) y: (1004,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'subset', 'essay_set': [5]}\n",
      "X: (4251, 15) y: (4251,)\n",
      "X: (1065, 15) y: (1065,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'subset', 'essay_set': [6]}\n",
      "X: (4300, 15) y: (4300,)\n",
      "X: (1070, 15) y: (1070,)\n",
      "####### {'model': 'XGB Regressor', 'text_set': 'subset', 'essay_set': [1, 3, 4, 5, 6]}\n",
      "X: (20998, 15) y: (20998,)\n",
      "X: (5219, 15) y: (5219,)\n"
     ]
    }
   ],
   "source": [
    "# rfc_class_ypred = []\n",
    "# xgb_class_ypred = []\n",
    "# xgb_regre_ypred = []\n",
    "\n",
    "# rfc_class_qwk = []\n",
    "# xgb_class_qwk = []\n",
    "# xgb_regre_qwk = []\n",
    "\n",
    "ypred_ls = []\n",
    "qwk_ls = []\n",
    "label_ls = []\n",
    "\n",
    "\n",
    "text_set_selection = ['original', 'subset']\n",
    "essay_set_selection = [[1], [3], [4], [5], [6], [1, 3, 4, 5, 6]]\n",
    "\n",
    "for text_set_ in text_set_selection:\n",
    "    for essay_set_ in essay_set_selection:\n",
    "        y_pred, qwk = test_randforest_classifier(text_set_, essay_set_)\n",
    "        ypred_ls.append(y_pred)\n",
    "        qwk_ls.append(qwk)\n",
    "        label_ls.append(text_set_+'_rfc;'+str(essay_set_))\n",
    "\n",
    "for text_set_ in text_set_selection:\n",
    "    for essay_set_ in essay_set_selection:\n",
    "        y_pred, qwk = test_xgb_classifier(text_set_, essay_set_)\n",
    "        ypred_ls.append(y_pred)\n",
    "        qwk_ls.append(qwk)\n",
    "        label_ls.append(text_set_+'_xgbcla;'+str(essay_set_))\n",
    "\n",
    "for text_set_ in text_set_selection:\n",
    "    for essay_set_ in essay_set_selection:\n",
    "        y_pred, qwk = test_xgb_regressor(text_set_, essay_set_)\n",
    "        ypred_ls.append(y_pred)\n",
    "        qwk_ls.append(qwk)\n",
    "        label_ls.append(text_set_+'_xgbreg;'+str(essay_set_))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba942e3b-dcb3-4b50-b8be-c7c8fe37ef2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original_rfc</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.741647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original_rfc</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.632297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original_rfc</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.696754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original_rfc</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.746570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original_rfc</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.664556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original_rfc</td>\n",
       "      <td>[1, 3, 4, 5, 6]</td>\n",
       "      <td>0.683907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>subset_rfc</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.712643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subset_rfc</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.616641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subset_rfc</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.654456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subset_rfc</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.739422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>subset_rfc</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.664943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subset_rfc</td>\n",
       "      <td>[1, 3, 4, 5, 6]</td>\n",
       "      <td>0.641670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original_xgbcla</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.570689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>original_xgbcla</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.669354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>original_xgbcla</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.701671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>original_xgbcla</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.748352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>original_xgbcla</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.669156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>original_xgbcla</td>\n",
       "      <td>[1, 3, 4, 5, 6]</td>\n",
       "      <td>0.640401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>subset_xgbcla</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.505758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>subset_xgbcla</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.613664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>subset_xgbcla</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.648069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>subset_xgbcla</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.737185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>subset_xgbcla</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.669295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>subset_xgbcla</td>\n",
       "      <td>[1, 3, 4, 5, 6]</td>\n",
       "      <td>0.606594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>original_xgbreg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.660368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>original_xgbreg</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.661016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>original_xgbreg</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.678724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>original_xgbreg</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.762742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>original_xgbreg</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.714949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>original_xgbreg</td>\n",
       "      <td>[1, 3, 4, 5, 6]</td>\n",
       "      <td>0.668794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>subset_xgbreg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.638803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>subset_xgbreg</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.620962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>subset_xgbreg</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.635245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>subset_xgbreg</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.738346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>subset_xgbreg</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.661815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>subset_xgbreg</td>\n",
       "      <td>[1, 3, 4, 5, 6]</td>\n",
       "      <td>0.643636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        essay_set       qwk\n",
       "0      original_rfc              [1]  0.741647\n",
       "1      original_rfc              [3]  0.632297\n",
       "2      original_rfc              [4]  0.696754\n",
       "3      original_rfc              [5]  0.746570\n",
       "4      original_rfc              [6]  0.664556\n",
       "5      original_rfc  [1, 3, 4, 5, 6]  0.683907\n",
       "6        subset_rfc              [1]  0.712643\n",
       "7        subset_rfc              [3]  0.616641\n",
       "8        subset_rfc              [4]  0.654456\n",
       "9        subset_rfc              [5]  0.739422\n",
       "10       subset_rfc              [6]  0.664943\n",
       "11       subset_rfc  [1, 3, 4, 5, 6]  0.641670\n",
       "12  original_xgbcla              [1]  0.570689\n",
       "13  original_xgbcla              [3]  0.669354\n",
       "14  original_xgbcla              [4]  0.701671\n",
       "15  original_xgbcla              [5]  0.748352\n",
       "16  original_xgbcla              [6]  0.669156\n",
       "17  original_xgbcla  [1, 3, 4, 5, 6]  0.640401\n",
       "18    subset_xgbcla              [1]  0.505758\n",
       "19    subset_xgbcla              [3]  0.613664\n",
       "20    subset_xgbcla              [4]  0.648069\n",
       "21    subset_xgbcla              [5]  0.737185\n",
       "22    subset_xgbcla              [6]  0.669295\n",
       "23    subset_xgbcla  [1, 3, 4, 5, 6]  0.606594\n",
       "24  original_xgbreg              [1]  0.660368\n",
       "25  original_xgbreg              [3]  0.661016\n",
       "26  original_xgbreg              [4]  0.678724\n",
       "27  original_xgbreg              [5]  0.762742\n",
       "28  original_xgbreg              [6]  0.714949\n",
       "29  original_xgbreg  [1, 3, 4, 5, 6]  0.668794\n",
       "30    subset_xgbreg              [1]  0.638803\n",
       "31    subset_xgbreg              [3]  0.620962\n",
       "32    subset_xgbreg              [4]  0.635245\n",
       "33    subset_xgbreg              [5]  0.738346\n",
       "34    subset_xgbreg              [6]  0.661815\n",
       "35    subset_xgbreg  [1, 3, 4, 5, 6]  0.643636"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame({'label': label_ls,'qwk': qwk_ls})\n",
    "output_df[['label', 'essay_set']] = output_df['label'].str.split(';', expand=True)\n",
    "output_df = output_df[['label', 'essay_set', 'qwk']]\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19764db5-034c-442c-b4ec-a3203d1d4889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86f14a-9f61-4032-b0dd-32be3b7f4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43b64368-3a96-4db7-bd2a-44a4a199c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('test_basic_features_qwk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc9916cf-1cad-48bc-81ae-630d19ac53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {col_name: col_values for col_name, col_values in zip(label_ls, ypred_ls)}\n",
    "\n",
    "# Create a DataFrame (pandas will automatically align lengths and fill missing values with NaN)\n",
    "ypred_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in data_dict.items()]))\n",
    "ypred_df.to_csv('test_basic_features_ypred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d742e4-86b0-4cd2-9a5e-9db8556ae516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9c173-499a-4b88-9c5d-0bb206c2b6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1ca29-5976-444e-94b3-24fa52f4efaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
